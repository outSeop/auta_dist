"""
ê°„ê²°í•œ ì¶œë ¥ìœ¼ë¡œ Knowledge Distillation ì‹¤í–‰
"""

import torch
import time
import sys
import os
from yolo_distillation.models.figma_ui_distillation import FigmaUIDistillation


def run_distillation_clean():
    """ë””ë²„ê¹… ì¶œë ¥ì„ ìµœì†Œí™”í•œ KD ì‹¤í–‰"""
    
    # ì„¤ì •
    config = {
        'teacher_model': '/content/auta_dist/weight/best_forest.pt',
        'student_model': 'yolo11s.yaml',
        'data_yaml': '/content/drive/MyDrive/Colab Notebooks/AUTA/data/yolo_dataset_webforest/data.yaml',
        'epochs': 10,
        'batch_size': 16,
        'learning_rate': 0.001,
        'num_workers': 8
    }
    
    print("ğŸš€ Figma UI Knowledge Distillation ì‹œì‘")
    print("=" * 50)
    
    try:
        # ëª¨ë¸ ì´ˆê¸°í™” (ë””ë²„ê¹… ë¹„í™œì„±í™”)
        print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
        distiller = FigmaUIDistillation(
            teacher_model=config['teacher_model'],
            student_model=config['student_model'], 
            data_yaml=config['data_yaml'],
            use_wandb=True,
            verbose_debug=False  # ë””ë²„ê¹… ì¶œë ¥ ì™„ì „ ë¹„í™œì„±í™”
        )
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        print(f"   Teacher: {distiller.teacher.model.model[-1].nc if hasattr(distiller.teacher.model.model[-1], 'nc') else 'N/A'} classes")
        print(f"   Student: {distiller.student.model.model[-1].nc if hasattr(distiller.student.model.model[-1], 'nc') else 'N/A'} classes")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    try:
        # í•™ìŠµ ì‹œì‘
        print(f"\nğŸ¯ í•™ìŠµ ì‹œì‘ ({config['epochs']} epochs)")
        print("-" * 30)
        
        best_map = distiller.train(
            epochs=config['epochs'],
            batch_size=config['batch_size'],
            learning_rate=config['learning_rate'],
            num_workers=config['num_workers']
        )
        
        print("\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        print(f"ğŸ“Š Best mAP: {best_map:.4f}")
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
        best_map = 0.0
    
    # ì„±ëŠ¥ ìš”ì•½
    print("\n" + "=" * 50)
    print("ğŸ“ˆ Knowledge Distillation ê²°ê³¼ ìš”ì•½")
    print("-" * 30)
    print(f"Teacher: YOLOv11-l (25M params)")
    print(f"Student: YOLOv11-s (9M params) - mAP: {best_map:.4f}")
    print(f"ì••ì¶•ë¥ : ~62% íŒŒë¼ë¯¸í„° ê°ì†Œ")
    print(f"WandB: https://wandb.ai/ ì—ì„œ ìƒì„¸ ê²°ê³¼ í™•ì¸")


if __name__ == "__main__":
    run_distillation_clean()
