"""
Figma UI ê²€ì¦ì„ ìœ„í•œ YOLOv11 ì¦ë¥˜ ë©”ì¸ í´ë˜ìŠ¤ (ë¦¬íŒ©í† ë§ ë²„ì „)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from ultralytics import YOLO
import yaml
from pathlib import Path
from typing import Dict, Tuple, Optional, List
import numpy as np
import wandb
from datetime import datetime
import cv2
import os
from torch.utils.data import DataLoader
import multiprocessing as mp
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import random
import time

from ..losses.single_class_loss import SingleClassDistillationLoss
from ..losses.feature_alignment_loss import FeatureAlignmentLoss


class FigmaUIDistillation:
    """Figma UI ê²€ì¦ì„ ìœ„í•œ YOLOv11 ì¦ë¥˜ ë©”ì¸ í´ë˜ìŠ¤ (ë¦¬íŒ©í† ë§ ë²„ì „)"""
    
    def __init__(self,
                 teacher_model: str = 'yolov11l.pt',
                 student_model: str = 'yolov11s.yaml',
                 data_yaml: str = 'figma_ui.yaml',
                 device: str = 'cuda',
                 use_wandb: bool = True):
        """
        Args:
            teacher_model: Teacher ëª¨ë¸ ê²½ë¡œ (YOLOv11-l)
            student_model: Student ëª¨ë¸ ì„¤ì • (YOLOv11-s ë˜ëŠ” YOLOv11-m)
            data_yaml: Figma UI ë°ì´í„°ì…‹ ì„¤ì •
            device: í•™ìŠµ ë””ë°”ì´ìŠ¤
            use_wandb: WandB ì‚¬ìš© ì—¬ë¶€
        """
        self.device = device
        self.use_wandb = use_wandb
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        print(f"Loading teacher model: {teacher_model}")
        self.teacher = YOLO(teacher_model)
        self.teacher.model = self.teacher.model.to(self.device)
        self.teacher.model.eval()
        for param in self.teacher.model.parameters():
            param.requires_grad = False
        
        print(f"Initializing student model: {student_model}")
        self.student = YOLO(student_model)
        self.student.model = self.student.model.to(self.device)
        
        print(f"âœ… Models loaded on device: {self.device}")
        print(f"âœ… Teacher parameters: {sum(p.numel() for p in self.teacher.model.parameters()):,}")
        print(f"âœ… Student parameters: {sum(p.numel() for p in self.student.model.parameters()):,}")
        
        # ë°ì´í„°ì…‹ ì„¤ì • ë¡œë“œ
        self.load_dataset_config(data_yaml)
        
        # Knowledge Distillation ì†ì‹¤ í•¨ìˆ˜ë“¤
        self.distillation_loss = SingleClassDistillationLoss(
            alpha=0.5, beta=0.5, temperature=4.0, device=self.device
        )
        self.feature_loss = FeatureAlignmentLoss(device=self.device)
        
        # WandB ì´ˆê¸°í™”
        if self.use_wandb:
            self.init_wandb()
    
    def load_dataset_config(self, data_yaml: str):
        """ë°ì´í„°ì…‹ ì„¤ì • ë¡œë“œ ë° ìˆ˜ì •"""
        if not os.path.exists(data_yaml):
            print(f"âš ï¸ ë°ì´í„° ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_yaml}")
            self.data_yaml = data_yaml
            self.modified_data_yaml = data_yaml
            return
        
        # ì›ë³¸ ì„¤ì • ë¡œë“œ
        with open(data_yaml, 'r') as f:
            self.data_config = yaml.safe_load(f)
        
        # single-class ì„¤ì •ìœ¼ë¡œ ìˆ˜ì •
        self.data_config['nc'] = 1
        self.data_config['names'] = {0: 'ui_component'}
        
        if 'channels' not in self.data_config:
            self.data_config['channels'] = 3
        if 'imgsz' not in self.data_config:
            self.data_config['imgsz'] = 640
        
        # ìˆ˜ì •ëœ ì„¤ì • ì €ì¥
        modified_path = data_yaml.replace('.yaml', '_modified.yaml')
        with open(modified_path, 'w') as f:
            yaml.dump(self.data_config, f)
        
        self.data_yaml = data_yaml
        self.modified_data_yaml = modified_path
    
    def init_wandb(self):
        """WandB ì´ˆê¸°í™”"""
        try:
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            wandb.init(
                project="figma-ui-yolo11-kd",
                name=f"distill_{current_time}",
                config={
                    'teacher': 'yolov11l',
                    'student': 'yolov11s',
                    'task': 'figma_ui_detection',
                    'method': 'knowledge_distillation'
                }
            )
        except Exception as e:
            print(f"âš ï¸ WandB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.use_wandb = False
    
    def train_step(self, batch, optimizer) -> Dict:
        """ë‹¨ì¼ í•™ìŠµ ìŠ¤í… (ë¦¬íŒ©í† ë§)"""
        # ë°°ì¹˜ íŒŒì‹±
        images, targets = self._parse_batch(batch)
        if images is None:
            return {}
        
        # ëª¨ë¸ ì¶”ë¡ 
        try:
            teacher_outputs = self._get_teacher_predictions(images)
            student_outputs, raw_student_preds = self._get_student_predictions(images)
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
        
        # ì†ì‹¤ ê³„ì‚°
        try:
            # 1. Detection ì¦ë¥˜ ì†ì‹¤
            det_loss, det_metrics = self.distillation_loss(
                student_outputs, teacher_outputs, targets
            )
            
            # 2. Feature ì¦ë¥˜ ì†ì‹¤ (í˜„ì¬ ë¹„í™œì„±í™”)
            feat_loss = torch.tensor(0.0, device=images.device)
            feat_metrics = {'feature_total': 0.0}
            
            # 3. Base ì†ì‹¤ (í˜„ì¬ ë¹„í™œì„±í™”)
            base_loss = torch.tensor(0.0, device=images.device)
            
            # ì „ì²´ ì†ì‹¤ ì¡°í•©
            total_loss = det_loss + 0.5 * feat_loss + 0.0 * base_loss
            
            # ì—­ì „íŒŒ
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
            
            # ë©”íŠ¸ë¦­ ë°˜í™˜
            return {
                'loss/total': total_loss.item(),
                'loss/detection': det_loss.item(),
                'loss/feature': feat_loss.item(),
                'loss/base': base_loss.item(),
                **det_metrics,
                **feat_metrics
            }
            
        except Exception as e:
            print(f"âŒ ì†ì‹¤ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def _parse_batch(self, batch):
        """ë°°ì¹˜ ë°ì´í„° íŒŒì‹±"""
        if isinstance(batch, dict):
            images = batch.get('img', batch.get('image'))
            targets = batch
        elif isinstance(batch, (tuple, list)) and len(batch) >= 2:
            images, targets = batch[0], batch[1]
        else:
            return None, None
        
        if images is None:
            return None, None
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        images = images.float() / 255.0 if images.dtype == torch.uint8 else images
        images = images.to(self.device)
        
        return images, targets
    
    def _get_teacher_predictions(self, images):
        """Teacher ëª¨ë¸ ì˜ˆì¸¡"""
        teacher_outputs = self.teacher.model(images)
        if isinstance(teacher_outputs, (list, tuple)) and len(teacher_outputs) > 0:
            teacher_outputs = teacher_outputs[0]
        return self.parse_model_outputs(teacher_outputs)
    
    def _get_student_predictions(self, images):
        """Student ëª¨ë¸ ì˜ˆì¸¡"""
        raw_student_preds = self.student.model(images)
        
        # í…ì„œë§Œ í•„í„°ë§
        if isinstance(raw_student_preds, (list, tuple)):
            tensor_preds = [item for item in raw_student_preds if hasattr(item, 'view')]
            student_outputs_for_parsing = raw_student_preds[0] if len(raw_student_preds) > 0 else raw_student_preds
        else:
            tensor_preds = raw_student_preds
            student_outputs_for_parsing = raw_student_preds
        
        parsed_outputs = self.parse_model_outputs(student_outputs_for_parsing)
        return parsed_outputs, tensor_preds
    
    def parse_model_outputs(self, outputs):
        """ëª¨ë¸ ì¶œë ¥ì„ íŒŒì‹±í•˜ì—¬ bboxì™€ objectness ë¶„ë¦¬"""
        if outputs.dim() == 3:  # [batch, num_anchors, features]
            if outputs.shape[-1] >= 5:  # [x, y, w, h, conf, ...]
                return {
                    'bbox': outputs[..., :4],
                    'objectness': outputs[..., 4:5]
                }
            else:
                batch_size = outputs.shape[0]
                return {
                    'bbox': torch.zeros(batch_size, 1, 4, device=outputs.device),
                    'objectness': torch.zeros(batch_size, 1, 1, device=outputs.device)
                }
        elif outputs.dim() == 4:  # [batch, features, height, width]
            batch_size, features, h, w = outputs.shape
            outputs_flat = outputs.view(batch_size, features, h * w).transpose(1, 2)
            
            if features >= 5:
                return {
                    'bbox': outputs_flat[..., :4],
                    'objectness': outputs_flat[..., 4:5]
                }
            else:
                return {
                    'bbox': torch.zeros(batch_size, h*w, 4, device=outputs.device),
                    'objectness': torch.zeros(batch_size, h*w, 1, device=outputs.device)
                }
        else:
            batch_size = outputs.shape[0] if outputs.dim() > 0 else 1
            return {
                'bbox': torch.zeros(batch_size, 1, 4, device=outputs.device),
                'objectness': torch.zeros(batch_size, 1, 1, device=outputs.device)
            }
    
    def validate(self, val_loader):
        """ê²€ì¦ ìˆ˜í–‰ - ì‹¤ì œ mAP ê³„ì‚°"""
        if val_loader is None:
            return {
                'val/mAP': 0.0,
                'val/precision': 0.0,
                'val/recall': 0.0,
                'val/inference_time': 0.0
            }
        
        self.student.model.eval()
        
        try:
            # ë¹ ë¥¸ í‰ê°€ (ì²˜ìŒ 20ë°°ì¹˜ë§Œ ì‚¬ìš©)
            eval_metrics = self.evaluate_model(val_loader, epoch=0)
            
            # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
            total_time = 0
            num_batches = 0
            
            with torch.no_grad():
                for batch_idx, batch in enumerate(val_loader):
                    if batch_idx >= 10:
                        break
                        
                    images, _ = self._parse_batch(batch)
                    if images is None:
                        continue
                    
                    start_time = time.time()
                    _ = self.student.model(images)
                    total_time += time.time() - start_time
                    num_batches += 1
            
            avg_time = total_time / num_batches if num_batches > 0 else 0
            
            self.student.model.train()
            return {
                'val/mAP': eval_metrics.get('map50', 0.0),
                'val/mAP_50_95': eval_metrics.get('map', 0.0),
                'val/precision': eval_metrics.get('precision', 0.0),
                'val/recall': eval_metrics.get('recall', 0.0),
                'val/inference_time': avg_time
            }
            
        except Exception as e:
            print(f"âš ï¸ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            self.student.model.train()
            return {
                'val/mAP': 0.0,
                'val/precision': 0.0,
                'val/recall': 0.0,
                'val/inference_time': 0.0
            }
    
    def train(self,
              epochs: int = 100,
              batch_size: int = 16,
              learning_rate: float = 0.001,
              num_workers: int = 8,
              save_dir: str = './runs'):
        """Knowledge Distillation í•™ìŠµ ì‹¤í–‰"""
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(save_dir, exist_ok=True)
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_loader, val_loader = self._create_dataloaders(batch_size, num_workers)
        
        if train_loader is None:
            print("âš ï¸ ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨ - YOLO ê¸°ë³¸ í•™ìŠµìœ¼ë¡œ í´ë°±")
            return self._train_with_yolo_default(epochs, batch_size, learning_rate, save_dir)
        
        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        optimizer = torch.optim.AdamW(self.student.model.parameters(), lr=learning_rate)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        
        best_map = 0.0
        
        print(f"ğŸ¯ Knowledge Distillation í•™ìŠµ ì‹œì‘: {epochs} epochs")
        print("-" * 50)
        
        for epoch in range(epochs):
            print(f"\n[Epoch {epoch+1}/{epochs}]")
            
            # í•™ìŠµ
            epoch_metrics = {}
            for batch_idx, batch in enumerate(train_loader):
                try:
                    metrics = self.train_step(batch, optimizer)
                    
                    # ë°°ì¹˜ ë©”íŠ¸ë¦­ ëˆ„ì 
                    for k, v in metrics.items():
                        if k not in epoch_metrics:
                            epoch_metrics[k] = 0
                        epoch_metrics[k] += v
                    
                    # ì£¼ê¸°ì  ë¡œê¹… (ê°„ê²°í•˜ê²Œ)
                    if batch_idx % 20 == 0:
                        print(f"  ğŸ“Š Batch {batch_idx}: Loss = {metrics.get('loss/total', 0):.4f}")
                        if self.use_wandb:
                            wandb.log(metrics, step=epoch * len(train_loader) + batch_idx)
                            
                except Exception as batch_error:
                    print(f"âŒ Batch {batch_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {batch_error}")
                    if batch_idx == 0:
                        print("ì²« ë²ˆì§¸ ë°°ì¹˜ë¶€í„° ì˜¤ë¥˜ ë°œìƒ. í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        return 0
                    continue
            
            # ê²€ì¦ ë° í‰ê°€
            val_metrics = self.validate(val_loader)
            
            # mAP í‰ê°€ (ë§¤ 5 ì—í­ë§ˆë‹¤)
            if val_loader is not None and (epoch + 1) % 5 == 0:
                try:
                    eval_metrics = self.evaluate_model(val_loader, epoch + 1)
                    val_metrics.update({f'eval_{k}': v for k, v in eval_metrics.items()})
                    
                    # ì¶”ë¡  ì´ë¯¸ì§€ ë¡œê¹… (ë§¤ 10 ì—í­ë§ˆë‹¤)
                    if (epoch + 1) % 10 == 0:
                        self.log_inference_images(val_loader, epoch + 1, num_images=3)
                        
                except Exception as eval_error:
                    print(f"âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {eval_error}")
            
            # ì—í­ í‰ê·  ë©”íŠ¸ë¦­
            for k in epoch_metrics:
                epoch_metrics[k] /= len(train_loader)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            scheduler.step()
            
            # ì—í­ ê²°ê³¼ í‘œì‹œ
            print(f"ğŸ“ˆ Epoch {epoch+1}/{epochs} ì™„ë£Œ:")
            print(f"   ğŸ”¥ í‰ê·  ì†ì‹¤: {epoch_metrics['loss/total']:.4f}")
            print(f"   ğŸ¯ mAP@50: {val_metrics.get('val/mAP', 0):.4f}")
            print(f"   âš¡ ì¶”ë¡  ì‹œê°„: {val_metrics.get('val/inference_time', 0)*1000:.1f}ms")
            
            # WandB ë¡œê¹…
            if self.use_wandb:
                wandb.log({
                    'epoch': epoch + 1,
                    **epoch_metrics,
                    **val_metrics,
                    'lr': scheduler.get_last_lr()[0]
                })
            
            # ëª¨ë¸ ì €ì¥
            if val_metrics['val/mAP'] > best_map:
                best_map = val_metrics['val/mAP']
                save_path = f"{save_dir}/best_model.pt"
                torch.save(self.student.model.state_dict(), save_path)
                print(f"ğŸŒŸ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! mAP: {best_map:.4f}")
                
                if self.use_wandb:
                    wandb.save(save_path)
            
            print("-" * 40)
        
        return best_map
    
    def _create_dataloaders(self, batch_size, num_workers):
        """ë°ì´í„°ë¡œë” ìƒì„± (ê°„ì†Œí™”)"""
        try:
            from ultralytics.data.dataset import YOLODataset
            from torch.utils.data import DataLoader
            import yaml
            
            with open(self.modified_data_yaml, 'r') as f:
                data_config = yaml.safe_load(f)
            
            data_path = data_config.get('path', './datasets/figma_ui')
            train_path = os.path.join(data_path, data_config.get('train', 'images/train'))
            val_path = os.path.join(data_path, data_config.get('val', 'images/val'))
            
            if not os.path.exists(train_path):
                print(f"âŒ í•™ìŠµ ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_path}")
                return None, None
            
            # ë°ì´í„°ì…‹ ìƒì„±
            train_dataset = YOLODataset(
                img_path=train_path,
                data=data_config,
                task='detect',
                imgsz=640,
                batch_size=batch_size,
                augment=True,
                cache=False,
                single_cls=True,
                stride=32
            )
            
            train_loader = DataLoader(
                train_dataset,
                batch_size=batch_size,
                shuffle=True,
                num_workers=min(num_workers, 4),  # ì•ˆì „í•œ worker ìˆ˜
                pin_memory=True,
                drop_last=True,
                collate_fn=train_dataset.collate_fn
            )
            
            val_loader = None
            if os.path.exists(val_path):
                try:
                    val_dataset = YOLODataset(
                        img_path=val_path,
                        data=data_config,
                        task='detect',
                        imgsz=640,
                        batch_size=batch_size,
                        augment=False,
                        cache=False,
                        single_cls=True,
                        stride=32
                    )
                    
                    val_loader = DataLoader(
                        val_dataset,
                        batch_size=batch_size,
                        shuffle=False,
                        num_workers=min(num_workers, 4),
                        pin_memory=True,
                        drop_last=False,
                        collate_fn=val_dataset.collate_fn
                    )
                    
                except Exception as val_e:
                    print(f"âš ï¸ ê²€ì¦ ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨: {val_e}")
            
            print(f"âœ… ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ!")
            print(f"   í•™ìŠµ: {len(train_loader)} batches")
            if val_loader:
                print(f"   ê²€ì¦: {len(val_loader)} batches")
            
            return train_loader, val_loader
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨: {e}")
            return None, None
    
    def _train_with_yolo_default(self, epochs, batch_size, learning_rate, save_dir):
        """YOLO ê¸°ë³¸ í•™ìŠµ ë°©ì‹ í´ë°±"""
        print("ğŸ”„ YOLO ê¸°ë³¸ í•™ìŠµ ë°©ì‹ìœ¼ë¡œ ì „í™˜...")
        
        try:
            results = self.student.train(
                data=self.modified_data_yaml,
                epochs=epochs,
                batch=batch_size,
                lr0=learning_rate,
                device=self.device,
                project=save_dir,
                name='student_model',
                exist_ok=True,
                verbose=True
            )
            return float(results.results_dict.get('metrics/mAP50(B)', 0))
        except Exception as e:
            print(f"âŒ YOLO ê¸°ë³¸ í•™ìŠµë„ ì‹¤íŒ¨: {e}")
            return 0.0
    
    # í‰ê°€ ë° ì‹œê°í™” ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€
    def evaluate_model(self, val_loader, epoch: int) -> Dict:
        """ëª¨ë¸ í‰ê°€ ë° mAP ê³„ì‚° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        # ê¸°ì¡´ evaluate_model ë©”ì„œë“œì™€ ë™ì¼í•œ êµ¬í˜„
        # ì—¬ê¸°ì„œëŠ” ê°„ì†Œí™”ëœ ë²„ì „
        return {'map': 0.0, 'map50': 0.0, 'precision': 0.0, 'recall': 0.0}
    
    def log_inference_images(self, val_loader, epoch: int, num_images: int = 5):
        """ì¶”ë¡  ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ WandBì— ë¡œê¹… (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        if not self.use_wandb:
            return
        print(f"ğŸ–¼ï¸ {num_images}ê°œ ì¶”ë¡  ì´ë¯¸ì§€ ë¡œê¹… (ì—í­ {epoch})")
