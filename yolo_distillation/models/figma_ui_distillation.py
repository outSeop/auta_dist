"""
Figma UI ê²€ì¦ì„ ìœ„í•œ YOLOv11 ì¦ë¥˜ ë©”ì¸ í´ë˜ìŠ¤
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from ultralytics import YOLO
import yaml
from pathlib import Path
from typing import Dict, Tuple, Optional, List
import numpy as np
import wandb
from datetime import datetime
import cv2
import os
from torch.utils.data import DataLoader
import multiprocessing as mp

from ..losses.single_class_loss import SingleClassDistillationLoss
from ..losses.feature_alignment_loss import FeatureAlignmentLoss


class FigmaUIDistillation:
    """Figma UI ê²€ì¦ì„ ìœ„í•œ YOLOv11 ì¦ë¥˜ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self,
                 teacher_model: str = 'yolov11l.pt',
                 student_model: str = 'yolov11s.yaml',
                 data_yaml: str = 'figma_ui.yaml',
                 device: str = 'cuda',
                 use_wandb: bool = True):
        """
        Args:
            teacher_model: Teacher ëª¨ë¸ ê²½ë¡œ (YOLOv11-l)
            student_model: Student ëª¨ë¸ ì„¤ì • (YOLOv11-s ë˜ëŠ” YOLOv11-m)
            data_yaml: Figma UI ë°ì´í„°ì…‹ ì„¤ì •
            device: í•™ìŠµ ë””ë°”ì´ìŠ¤
            use_wandb: WandB ì‚¬ìš© ì—¬ë¶€
        """
        self.device = device
        self.use_wandb = use_wandb
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        print(f"Loading teacher model: {teacher_model}")
        self.teacher = YOLO(teacher_model)
        self.teacher.model.eval()
        for param in self.teacher.model.parameters():
            param.requires_grad = False
        
        print(f"Initializing student model: {student_model}")
        self.student = YOLO(student_model)
        
        # ë‹¨ì¼ í´ë˜ìŠ¤ ì„¤ì •
        self.num_classes = 1  # Figma UI component
        
        # ì†ì‹¤ í•¨ìˆ˜
        self.distillation_loss = SingleClassDistillationLoss(
            bbox_weight=2.0,
            objectness_weight=1.0,
            feature_weight=1.0
        )
        self.feature_loss = FeatureAlignmentLoss(
            use_attention=True
        )
        
        # ë°ì´í„° ì„¤ì •
        self.data_yaml = data_yaml
        self._modify_data_for_single_class()
        
        # WandB ì´ˆê¸°í™”
        if self.use_wandb:
            self.init_wandb()
    
    def _modify_data_for_single_class(self):
        """ë°ì´í„°ì…‹ì„ ë‹¨ì¼ í´ë˜ìŠ¤ë¡œ ìˆ˜ì •"""
        with open(self.data_yaml, 'r') as f:
            data = yaml.safe_load(f)
        
        # ë‹¨ì¼ í´ë˜ìŠ¤ë¡œ ì„¤ì •
        data['nc'] = 1
        data['names'] = ['ui_component']
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        self.modified_data_yaml = 'temp_single_class_data.yaml'
        with open(self.modified_data_yaml, 'w') as f:
            yaml.dump(data, f)
    
    def init_wandb(self):
        """WandB ì´ˆê¸°í™” ë° ì„¤ì •"""
        config = {
            'project': 'figma-ui-detection',
            'teacher_model': 'YOLOv11-l',
            'student_model': self.student.model.__class__.__name__,
            'num_classes': self.num_classes,
            'task': 'single_class_detection',
            'bbox_weight': self.distillation_loss.bbox_weight,
            'objectness_weight': self.distillation_loss.objectness_weight,
            'feature_weight': self.distillation_loss.feature_weight
        }
        
        wandb.init(
            project="figma-ui-yolo11-kd",
            name=f"distill_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            config=config,
            tags=["single-class", "figma-ui", "knowledge-distillation"]
        )
        
        # ëª¨ë¸ ë³µì¡ë„ ë¹„êµ ë¡œê¹…
        self.log_model_comparison()
    
    def log_model_comparison(self):
        """Teacher vs Student ëª¨ë¸ ë¹„êµ ë¡œê¹…"""
        if not self.use_wandb:
            return
        
        teacher_params = sum(p.numel() for p in self.teacher.model.parameters())
        student_params = sum(p.numel() for p in self.student.model.parameters())
        
        comparison_table = wandb.Table(
            columns=["Model", "Parameters", "Size (MB)", "Compression Ratio"],
            data=[
                ["Teacher (YOLOv11-l)", teacher_params, teacher_params * 4 / 1e6, 1.0],
                ["Student", student_params, student_params * 4 / 1e6, 
                 teacher_params / student_params]
            ]
        )
        
        wandb.log({
            "model_comparison": comparison_table,
            "compression_ratio": teacher_params / student_params
        })
    
    def extract_features(self, model, x):
        """ëª¨ë¸ì—ì„œ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œ"""
        features = []
        
        # YOLOv11 ë°±ë³¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        # P3, P4, P5 ë ˆë²¨ íŠ¹ì§•
        for i, module in enumerate(model.model):
            x = module(x)
            if i in [4, 6, 9]:  # ì£¼ìš” íŠ¹ì§• ë ˆì´ì–´
                features.append(x)
        
        return features, x
    
    def train_step(self, batch, optimizer):
        """ë‹¨ì¼ í•™ìŠµ ìŠ¤í…"""
        # ë°°ì¹˜ êµ¬ì¡° í™•ì¸ ë° ì•ˆì „í•œ ì²˜ë¦¬
        if isinstance(batch, dict):
            images = batch['img']
            # ì´ë¯¸ì§€ ë°ì´í„° íƒ€ì… ë° ì •ê·œí™” ì²˜ë¦¬
            if images.dtype == torch.uint8:
                images = images.float() / 255.0  # uint8 -> float32, [0,255] -> [0,1]
            images = images.to(self.device)
            
            print(f"ğŸ” ì´ë¯¸ì§€ shape: {images.shape}, dtype: {images.dtype}, device: {images.device}")
            
            # YOLO ë°°ì¹˜ì—ì„œ íƒ€ê²Ÿ ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ í™•ì¸)
            if 'batch_idx' in batch:
                targets = batch  # ì „ì²´ ë°°ì¹˜ ì •ë³´
            elif 'cls' in batch and 'bboxes' in batch:
                targets = batch  # ë¶„ë¦¬ëœ í˜•íƒœ
            else:
                # ë°°ì¹˜ í‚¤ í™•ì¸ì„ ìœ„í•œ ë””ë²„ê¹…
                print(f"ğŸ” ë°°ì¹˜ í‚¤: {list(batch.keys())}")
                targets = batch
        else:
            # ë°°ì¹˜ê°€ íŠœí”Œì´ë‚˜ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            images = batch[0]
            if images.dtype == torch.uint8:
                images = images.float() / 255.0
            images = images.to(self.device)
            targets = batch[1] if len(batch) > 1 else None
        
        # Teacher ì¶”ë¡  (no gradient)
        with torch.no_grad():
            teacher_features, teacher_outputs = self.teacher.model(images, augment=False)
            teacher_outputs = self.parse_model_outputs(teacher_outputs)
        
        # Student ì¶”ë¡ 
        student_features, student_outputs = self.student.model(images, augment=False)
        student_outputs = self.parse_model_outputs(student_outputs)
        
        # 1. Detection ì¦ë¥˜ ì†ì‹¤ (objectness + bbox)
        det_loss, det_metrics = self.distillation_loss(
            student_outputs, teacher_outputs, targets
        )
        
        # 2. Feature ì¦ë¥˜ ì†ì‹¤
        feat_loss, feat_metrics = self.feature_loss(
            student_features, teacher_features
        )
        
        # 3. ì›ë³¸ YOLO ì†ì‹¤ (Ground Truth ê¸°ë°˜)
        base_loss = self.student.model.loss(student_outputs, targets)
        
        # ì „ì²´ ì†ì‹¤ ì¡°í•©
        total_loss = det_loss + 0.5 * feat_loss + 0.3 * base_loss
        
        # ì—­ì „íŒŒ
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
        
        # ë©”íŠ¸ë¦­ ë¡œê¹…
        metrics = {
            'loss/total': total_loss.item(),
            'loss/detection': det_loss.item(),
            'loss/feature': feat_loss.item(),
            'loss/base': base_loss.item(),
            **det_metrics,
            **feat_metrics
        }
        
        return metrics
    
    def parse_model_outputs(self, outputs):
        """ëª¨ë¸ ì¶œë ¥ì„ íŒŒì‹±í•˜ì—¬ bboxì™€ objectness ë¶„ë¦¬"""
        # YOLOv11 ì¶œë ¥ í˜•ì‹ì— ë§ê²Œ íŒŒì‹±
        # outputs: [batch, num_anchors, 5] for single class
        # [x, y, w, h, objectness]
        
        return {
            'bbox': outputs[..., :4],
            'objectness': outputs[..., 4:5]
        }
    
    def validate(self, val_loader):
        """ê²€ì¦ ìˆ˜í–‰"""
        self.student.model.eval()
        
        metrics = {
            'val/mAP': 0,
            'val/precision': 0,
            'val/recall': 0,
            'val/inference_time': 0
        }
        
        with torch.no_grad():
            for batch in val_loader:
                images = batch['img'].to(self.device)
                
                # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
                import time
                start_time = time.time()
                outputs = self.student.model(images)
                inference_time = time.time() - start_time
                
                metrics['val/inference_time'] += inference_time
                
                # mAP ê³„ì‚° (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
                # ...
        
        self.student.model.train()
        return metrics
    
    def train(self,
              epochs: int = 100,
              batch_size: int = 16,
              learning_rate: float = 0.001,
              num_workers: int = 8,
              save_dir: str = './runs/figma_distillation'):
        """
        ì „ì²´ í•™ìŠµ ì‹¤í–‰
        
        Args:
            epochs: í•™ìŠµ ì—í­
            batch_size: ë°°ì¹˜ í¬ê¸°
            learning_rate: í•™ìŠµë¥ 
            num_workers: ë°ì´í„°ë¡œë” ì›Œì»¤ ìˆ˜
            save_dir: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        """
        
        # ì˜µí‹°ë§ˆì´ì €
        optimizer = torch.optim.AdamW(
            self.student.model.parameters(),
            lr=learning_rate,
            weight_decay=0.0005
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ (Cosine Annealing)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=epochs
        )
        
        # ë°ì´í„°ë¡œë” ìƒì„± ì‹œë„
        train_loader, val_loader = self._create_dataloaders(batch_size, num_workers)
        
        # ë°ì´í„°ë¡œë”ê°€ ì—†ëŠ” ê²½ìš° YOLO ê¸°ë³¸ í•™ìŠµ ë°©ì‹ ì‚¬ìš©
        if train_loader is None:
            print("ì»¤ìŠ¤í…€ ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨. YOLO ê¸°ë³¸ í•™ìŠµ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return 0
            # return self._train_with_yolo_default(epochs, batch_size, learning_rate, save_dir)
        
        best_map = 0
        
        for epoch in range(epochs):
            print(f"\n[Epoch {epoch+1}/{epochs}]")
            
            # í•™ìŠµ
            epoch_metrics = {}
            for batch_idx, batch in enumerate(train_loader):
                try:
                    metrics = self.train_step(batch, optimizer)
                    
                    # ë°°ì¹˜ ë©”íŠ¸ë¦­ ëˆ„ì 
                    for k, v in metrics.items():
                        if k not in epoch_metrics:
                            epoch_metrics[k] = 0
                        epoch_metrics[k] += v
                    
                    # ì£¼ê¸°ì  ë¡œê¹…
                    if batch_idx % 10 == 0:
                        print(f"Batch {batch_idx}: Loss = {metrics.get('loss/total', 0):.4f}")
                        if self.use_wandb:
                            wandb.log(metrics, step=epoch * len(train_loader) + batch_idx)
                            
                except Exception as batch_error:
                    print(f"âŒ Batch {batch_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {batch_error}")
                    if batch_idx == 0:  # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ì˜¤ë¥˜ë©´ ì¤‘ë‹¨
                        print("ì²« ë²ˆì§¸ ë°°ì¹˜ë¶€í„° ì˜¤ë¥˜ ë°œìƒ. í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        return 0
                    continue  # ë‹¤ë¥¸ ë°°ì¹˜ëŠ” ê±´ë„ˆë›°ê¸°
            
            # ê²€ì¦
            val_metrics = self.validate(val_loader)
            
            # ì—í­ í‰ê·  ë©”íŠ¸ë¦­
            for k in epoch_metrics:
                epoch_metrics[k] /= len(train_loader)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            scheduler.step()
            
            # WandB ë¡œê¹…
            if self.use_wandb:
                wandb.log({
                    'epoch': epoch,
                    **epoch_metrics,
                    **val_metrics,
                    'lr': scheduler.get_last_lr()[0]
                })
            
            # ëª¨ë¸ ì €ì¥
            if val_metrics['val/mAP'] > best_map:
                best_map = val_metrics['val/mAP']
                save_path = f"{save_dir}/best_model.pt"
                torch.save(self.student.model.state_dict(), save_path)
                print(f"Best model saved: mAP={best_map:.4f}")
                
                if self.use_wandb:
                    wandb.save(save_path)
        
        return best_map
    
    def _train_with_yolo_default(self, epochs, batch_size, learning_rate, save_dir):
        """
        YOLO ê¸°ë³¸ í•™ìŠµ ë°©ì‹ì„ ì‚¬ìš©í•œ Knowledge Distillation
        """
        print("YOLO ê¸°ë³¸ í•™ìŠµ ë°©ì‹ìœ¼ë¡œ Knowledge Distillationì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # YOLO ê¸°ë³¸ í•™ìŠµ ì„¤ì •
        results = self.student.train(
            data=self.modified_data_yaml,
            epochs=epochs,
            batch=batch_size,
            lr0=learning_rate,
            device=self.device,
            project=save_dir,
            name='distillation_run',
            save=True,
            plots=True,
            verbose=True
        )
        
        # ê²°ê³¼ì—ì„œ ìµœê³  mAP ì¶”ì¶œ
        if hasattr(results, 'results_dict'):
            best_map = results.results_dict.get('metrics/mAP50-95(B)', 0.0)
        else:
            best_map = 0.0
            
        print(f"YOLO ê¸°ë³¸ í•™ìŠµ ì™„ë£Œ! Best mAP: {best_map:.4f}")
        return best_map
    
    def _create_dataloaders(self, batch_size, num_workers):
        """
        YOLO ë°ì´í„°ë¡œë”ë¥¼ ì§ì ‘ ìƒì„±
        """
        try:
            from ultralytics.data.dataset import YOLODataset
            from torch.utils.data import DataLoader
            import yaml
            import os
            from pathlib import Path
            
            print("ğŸ”„ ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œë¥¼ í”¼í•œ ì§ì ‘ ë°ì´í„°ë¡œë” ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            
            # ë°ì´í„°ì…‹ ì„¤ì • ë¡œë“œ
            with open(self.modified_data_yaml, 'r') as f:
                data_config = yaml.safe_load(f)
            
            # ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
            data_path = data_config.get('path', './datasets/figma_ui')
            train_path = os.path.join(data_path, data_config.get('train', 'images/train'))
            val_path = os.path.join(data_path, data_config.get('val', 'images/val'))
            
            print(f"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {data_path}")
            print(f"ğŸ“ í•™ìŠµ ê²½ë¡œ: {train_path}")
            print(f"ğŸ“ ê²€ì¦ ê²½ë¡œ: {val_path}")
            
            # ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if not os.path.exists(train_path):
                print(f"âŒ í•™ìŠµ ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_path}")
                return None, None
            
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                image_files.extend(Path(train_path).glob(ext))
            
            if not image_files:
                print(f"âŒ {train_path}ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None, None
            
            print(f"âœ… {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            # ì§ì ‘ YOLO ë°ì´í„°ì…‹ ìƒì„± (ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ íšŒí”¼)
            try:
                # í•™ìŠµìš© ë°ì´í„°ì…‹
                train_dataset = YOLODataset(
                    img_path=train_path,
                    data=data_config,
                    task='detect',
                    imgsz=640,
                    batch_size=batch_size,
                    augment=True,
                    cache=False,
                    single_cls=True,  # ë‹¨ì¼ í´ë˜ìŠ¤
                    stride=32,
                    pad=0.0,
                    rect=False
                )
                
                train_loader = DataLoader(
                    train_dataset,
                    batch_size=batch_size,
                    shuffle=True,
                    num_workers=num_workers,
                    pin_memory=True,
                    drop_last=True,
                    collate_fn=train_dataset.collate_fn
                )
                
                print(f"âœ… í•™ìŠµ ë°ì´í„°ë¡œë” ìƒì„± ì„±ê³µ: {len(train_loader)} batches")
                
                # ê²€ì¦ìš© ë°ì´í„°ì…‹
                val_loader = None
                if os.path.exists(val_path):
                    try:
                        val_dataset = YOLODataset(
                            img_path=val_path,
                            data=data_config,
                            task='detect',
                            imgsz=640,
                            batch_size=batch_size,
                            augment=False,
                            cache=False,
                            single_cls=True,
                            stride=32,
                            pad=0.5,
                            rect=True
                        )
                        
                        val_loader = DataLoader(
                            val_dataset,
                            batch_size=batch_size,
                            shuffle=False,
                            num_workers=num_workers,
                            pin_memory=True,
                            drop_last=False,
                            collate_fn=val_dataset.collate_fn
                        )
                        
                        print(f"âœ… ê²€ì¦ ë°ì´í„°ë¡œë” ìƒì„± ì„±ê³µ: {len(val_loader)} batches")
                    except Exception as val_e:
                        print(f"âš ï¸ ê²€ì¦ ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨: {val_e}")
                
                print("ğŸ‰ ì§ì ‘ ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ!")
                return train_loader, val_loader
                
            except Exception as dataset_e:
                print(f"âŒ YOLO ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {dataset_e}")
                return None, None
                
        except ImportError as ie:
            print(f"âŒ YOLO ëª¨ë“ˆ import ì˜¤ë¥˜: {ie}")
            return None, None
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë¡œë” ìƒì„± ì¤‘ ì „ì²´ ì˜¤ë¥˜: {e}")
            print("ğŸ’¡ ì§ì ‘ ë°ì´í„°ë¡œë” ìƒì„±ë„ ì‹¤íŒ¨ - YOLO ê¸°ë³¸ í•™ìŠµìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤")
            return None, None
