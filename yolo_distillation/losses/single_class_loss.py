"""
ë‹¨ì¼ í´ë˜ìŠ¤ ê°ì²´ íƒì§€ë¥¼ ìœ„í•œ ì¦ë¥˜ ì†ì‹¤ í´ë˜ìŠ¤
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple


class SingleClassDistillationLoss(nn.Module):
    """ë‹¨ì¼ í´ë˜ìŠ¤ ê°ì²´ íƒì§€ë¥¼ ìœ„í•œ ì¦ë¥˜ ì†ì‹¤"""
    
    def __init__(self, 
                 bbox_weight: float = 2.0,
                 objectness_weight: float = 1.0,
                 feature_weight: float = 1.0,
                 iou_threshold: float = 0.5):
        """
        Args:
            bbox_weight: Bounding box regression ì¦ë¥˜ ê°€ì¤‘ì¹˜
            objectness_weight: Objectness score ì¦ë¥˜ ê°€ì¤‘ì¹˜  
            feature_weight: Feature ì¦ë¥˜ ê°€ì¤‘ì¹˜
            iou_threshold: Positive sampleì„ ìœ„í•œ IoU ì„ê³„ê°’
        """
        super().__init__()
        self.bbox_weight = bbox_weight
        self.objectness_weight = objectness_weight
        self.feature_weight = feature_weight
        self.iou_threshold = iou_threshold
        
        # ì†ì‹¤ í•¨ìˆ˜ë“¤
        self.mse_loss = nn.MSELoss(reduction='none')
        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')
        self.smooth_l1 = nn.SmoothL1Loss(reduction='none')
        
    def forward(self, 
                student_outputs: Dict,
                teacher_outputs: Dict,
                targets: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """
        ë‹¨ì¼ í´ë˜ìŠ¤ ì¦ë¥˜ ì†ì‹¤ ê³„ì‚°
        
        Args:
            student_outputs: Student ëª¨ë¸ ì¶œë ¥ (bbox, objectness)
            teacher_outputs: Teacher ëª¨ë¸ ì¶œë ¥ (bbox, objectness)
            targets: Ground truth íƒ€ê²Ÿ
        
        Returns:
            total_loss: ì „ì²´ ì†ì‹¤
            loss_dict: ê°œë³„ ì†ì‹¤ ë”•ì…”ë„ˆë¦¬
        """
        
        # 1. Objectness Score ì¦ë¥˜ (ê°ì²´ ì¡´ì¬ í™•ë¥ )
        student_obj = student_outputs['objectness']  # [B, N, 1]
        teacher_obj = teacher_outputs['objectness'].detach()
        
        print(f"ğŸ” Student objectness shape: {student_obj.shape}")
        print(f"ğŸ” Teacher objectness shape: {teacher_obj.shape}")
        
        # ì§€ëŠ¥ì  ì°¨ì› ì •ë ¬ (ì •ë³´ ì†ì‹¤ ìµœì†Œí™”)
        if student_obj.shape != teacher_obj.shape:
            teacher_obj, student_obj = self.align_outputs_intelligently(teacher_obj, student_obj)
            print(f"ğŸ”§ ì§€ëŠ¥ì  ì°¨ì› ì¡°ì • í›„ - Student: {student_obj.shape}, Teacher: {teacher_obj.shape}")
        
        # Teacherì˜ objectnessë¥¼ soft labelë¡œ ì‚¬ìš©
        try:
            obj_loss = F.binary_cross_entropy_with_logits(
                student_obj,
                torch.sigmoid(teacher_obj),
                reduction='mean'
            )
        except Exception as obj_error:
            print(f"âŒ Objectness ì†ì‹¤ ê³„ì‚° ì˜¤ë¥˜: {obj_error}")
            obj_loss = torch.tensor(0.0, device=student_obj.device)
        
        # 2. Bounding Box Regression ì¦ë¥˜
        student_bbox = student_outputs['bbox']  # [B, N, 4]
        teacher_bbox = teacher_outputs['bbox'].detach()
        
        print(f"ğŸ” Student bbox shape: {student_bbox.shape}")
        print(f"ğŸ” Teacher bbox shape: {teacher_bbox.shape}")
        
        # ì§€ëŠ¥ì  ì°¨ì› ì •ë ¬ (BBoxë„ ë™ì¼í•˜ê²Œ)
        if student_bbox.shape != teacher_bbox.shape:
            teacher_bbox, student_bbox = self.align_outputs_intelligently(teacher_bbox, student_bbox)
            print(f"ğŸ”§ BBox ì§€ëŠ¥ì  ì°¨ì› ì¡°ì • í›„ - Student: {student_bbox.shape}, Teacher: {teacher_bbox.shape}")
        
        # Teacher confidenceê°€ ë†’ì€ ì˜ˆì¸¡ë§Œ ì‚¬ìš©
        try:
            high_conf_mask = torch.sigmoid(teacher_obj) > 0.5  # [B, N, 1]
            high_conf_mask_bbox = high_conf_mask.squeeze(-1)   # [B, N] for bbox indexing
            
            print(f"ğŸ” high_conf_mask shape: {high_conf_mask.shape}")
            print(f"ğŸ” high_conf_mask_bbox shape: {high_conf_mask_bbox.shape}")
            
            if high_conf_mask.any():
                # BBox ë§ˆìŠ¤í‚¹ - ì°¨ì› ë§ì¶¤
                student_bbox_masked = student_bbox[high_conf_mask_bbox]  # [num_valid, 4]
                teacher_bbox_masked = teacher_bbox[high_conf_mask_bbox]  # [num_valid, 4]
                
                print(f"ğŸ” Masked student_bbox shape: {student_bbox_masked.shape}")
                print(f"ğŸ” Masked teacher_bbox shape: {teacher_bbox_masked.shape}")
                
                # IoU loss + L1 loss ì¡°í•©
                bbox_loss = self.bbox_distillation_loss(
                    student_bbox_masked,
                    teacher_bbox_masked
                )
            else:
                bbox_loss = torch.tensor(0.0, device=student_obj.device)
        except Exception as bbox_error:
            print(f"âŒ BBox ì†ì‹¤ ê³„ì‚° ì˜¤ë¥˜: {bbox_error}")
            bbox_loss = torch.tensor(0.0, device=student_obj.device)
        
        # 3. Localization Quality ì¦ë¥˜
        # Teacherì˜ localization qualityë¥¼ ì „ë‹¬
        print(f"ğŸ” Forwardì—ì„œ targets ì „ë‹¬ - íƒ€ì…: {type(targets)}")
        if hasattr(targets, 'shape'):
            print(f"ğŸ” Forwardì—ì„œ targets shape: {targets.shape}")
        
        loc_quality = self.compute_localization_quality(
            teacher_bbox, teacher_obj, targets
        )
        
        loc_loss = self.localization_quality_loss(
            student_bbox, student_obj, loc_quality
        )
        
        # ì „ì²´ ì†ì‹¤ ê³„ì‚°
        total_loss = (
            self.objectness_weight * obj_loss +
            self.bbox_weight * bbox_loss +
            self.feature_weight * loc_loss
        )
        
        loss_dict = {
            'objectness_loss': obj_loss.item(),
            'bbox_loss': bbox_loss.item() if isinstance(bbox_loss, torch.Tensor) else bbox_loss,
            'localization_loss': loc_loss.item(),
            'total_loss': total_loss.item()
        }
        
        return total_loss, loss_dict
    
    def bbox_distillation_loss(self, student_bbox, teacher_bbox):
        """Bounding Box ì¦ë¥˜ ì†ì‹¤ (IoU + L1)"""
        print(f"ğŸ” BBox ì†ì‹¤ ê³„ì‚° - Student shape: {student_bbox.shape}, Teacher shape: {teacher_bbox.shape}")
        
        # ë„ˆë¬´ ë§ì€ ë°•ìŠ¤ê°€ ìˆìœ¼ë©´ ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ ì ˆì•½)
        if student_bbox.shape[0] > 10000:
            indices = torch.randperm(student_bbox.shape[0])[:10000]
            student_bbox = student_bbox[indices]
            teacher_bbox = teacher_bbox[indices]
            print(f"ğŸ”§ ìƒ˜í”Œë§ í›„ - Student: {student_bbox.shape}, Teacher: {teacher_bbox.shape}")
        
        try:
            # YOLO bbox í˜•ì‹ (cx, cy, w, h) â†’ (x1, y1, x2, y2) ë³€í™˜
            student_bbox_xyxy = self.xywh_to_xyxy(student_bbox)
            teacher_bbox_xyxy = self.xywh_to_xyxy(teacher_bbox)
            
            # CIoU/DIoU loss ê³„ì‚°
            iou_loss = self.compute_ciou_loss(student_bbox_xyxy, teacher_bbox_xyxy)
            
            # L1 smooth loss (ì›ë³¸ ì¢Œí‘œì—ì„œ)
            l1_loss = self.smooth_l1(student_bbox, teacher_bbox).mean()
            
            return iou_loss + l1_loss
            
        except Exception as e:
            print(f"âŒ BBox ì†ì‹¤ ì„¸ë¶€ ì˜¤ë¥˜: {e}")
            return torch.tensor(0.0, device=student_bbox.device)
    
    def compute_ciou_loss(self, pred_boxes, target_boxes):
        """Complete IoU Loss ê³„ì‚°"""
        # ê°„ë‹¨í•œ IoU loss êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ CIoU í•„ìš”)
        iou = self.box_iou(pred_boxes, target_boxes)
        return (1 - iou).mean()
    
    def box_iou(self, box1, box2):
        """IoU ê³„ì‚°"""
        # box1, box2: [N, 4] (x1, y1, x2, y2)
        print(f"ğŸ” IoU ê³„ì‚° - box1: {box1.shape}, box2: {box2.shape}")
        
        # Shape í™•ì¸
        if box1.shape != box2.shape:
            print(f"âš ï¸ Shape ë¶ˆì¼ì¹˜: {box1.shape} vs {box2.shape}")
            min_len = min(box1.shape[0], box2.shape[0])
            box1 = box1[:min_len]
            box2 = box2[:min_len]
            print(f"ğŸ”§ Shape ì¡°ì • í›„: {box1.shape}, {box2.shape}")
        
        # ìœ íš¨í•œ ë°•ìŠ¤ë§Œ ì²˜ë¦¬ (ë„ˆë¹„ì™€ ë†’ì´ê°€ ì–‘ìˆ˜ì¸ ê²ƒ)
        valid_mask1 = (box1[:, 2] > box1[:, 0]) & (box1[:, 3] > box1[:, 1])
        valid_mask2 = (box2[:, 2] > box2[:, 0]) & (box2[:, 3] > box2[:, 1])
        valid_mask = valid_mask1 & valid_mask2
        
        if not valid_mask.any():
            print("âš ï¸ ìœ íš¨í•œ ë°•ìŠ¤ê°€ ì—†ìŒ")
            return torch.zeros(box1.shape[0], device=box1.device)
        
        area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])
        area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])
        
        inter_x1 = torch.max(box1[:, 0], box2[:, 0])
        inter_y1 = torch.max(box1[:, 1], box2[:, 1])
        inter_x2 = torch.min(box1[:, 2], box2[:, 2])
        inter_y2 = torch.min(box1[:, 3], box2[:, 3])
        
        inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * \
                    torch.clamp(inter_y2 - inter_y1, min=0)
        
        union_area = area1 + area2 - inter_area
        iou = torch.zeros_like(area1)
        iou[valid_mask] = inter_area[valid_mask] / (union_area[valid_mask] + 1e-6)
        
        return iou
    
    def compute_localization_quality(self, bbox, objectness, targets):
        """Teacherì˜ localization quality ê³„ì‚°"""
        # Teacher ì˜ˆì¸¡ê³¼ GT ê°„ì˜ IoUë¥¼ quality scoreë¡œ ì‚¬ìš©
        quality_scores = []
        
        print(f"ğŸ” Targets íƒ€ì…: {type(targets)}")
        print(f"ğŸ” Targets í˜•íƒœ: {targets.shape if hasattr(targets, 'shape') else 'No shape'}")
        if hasattr(targets, 'keys'):
            print(f"ğŸ” Targets keys: {targets.keys()}")
        if isinstance(targets, (list, tuple)):
            print(f"ğŸ” Targets ê¸¸ì´: {len(targets)}")
            if len(targets) > 0:
                print(f"ğŸ” ì²« ë²ˆì§¸ Target íƒ€ì…: {type(targets[0])}")
                print(f"ğŸ” ì²« ë²ˆì§¸ Target: {targets[0]}")
        
        # targets í˜•íƒœì— ë”°ë¥¸ ì²˜ë¦¬
        if isinstance(targets, torch.Tensor):
            # Tensor í˜•íƒœì¸ ê²½ìš° ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
            batch_size = targets.shape[0] if targets.dim() > 0 else 1
            for i in range(batch_size):
                if targets.dim() > 1 and targets.shape[1] > 0:
                        target_i = targets[i] if targets.dim() > 1 else targets
                        if len(target_i.shape) > 0 and target_i.shape[0] > 0:
                            # Teacher ì˜ˆì¸¡ê³¼ GT ë§¤ì¹­
                            teacher_conf = torch.sigmoid(objectness[i])  # [N, 1]
                            high_conf_idx = teacher_conf.squeeze(-1) > 0.5  # [N] for bbox indexing
                            
                            if high_conf_idx.any():
                                teacher_boxes = bbox[i][high_conf_idx]  # [num_valid, 4]
                                # targetsê°€ [batch, max_labels, 6] í˜•íƒœì¼ ìˆ˜ ìˆìŒ (class, x, y, w, h, conf)
                                if target_i.shape[-1] >= 5:
                                    gt_boxes = target_i[:, 1:5] if target_i.shape[-1] > 5 else target_i[:, :4]  
                                else:
                                    gt_boxes = target_i[:, :4]  # ì´ë¯¸ bboxë§Œ ìˆëŠ” ê²½ìš°
                                
                                # GT ë°•ìŠ¤ê°€ ìˆëŠ” ê²½ìš°ë§Œ IoU ê³„ì‚°
                                if gt_boxes.shape[0] > 0:
                                    ious = self.box_iou(teacher_boxes, gt_boxes)
                                    quality = ious.max(dim=1)[0]
                                    quality_scores.append(quality)
        
        elif isinstance(targets, (list, tuple)):
            # List í˜•íƒœì¸ ê²½ìš°
            for i in range(len(targets)):
                if len(targets[i]) > 0:
                    # Teacher ì˜ˆì¸¡ê³¼ GT ë§¤ì¹­
                    teacher_conf = torch.sigmoid(objectness[i])  # [N, 1]
                    high_conf_idx = teacher_conf.squeeze(-1) > 0.5  # [N] for bbox indexing
                    
                    if high_conf_idx.any():
                        teacher_boxes = bbox[i][high_conf_idx]  # [num_valid, 4]
                        gt_boxes = targets[i][:, 1:5] if targets[i].shape[-1] > 4 else targets[i][:, :4]
                        # ë””ë°”ì´ìŠ¤ ë° dtype ì •ë ¬
                        gt_boxes = gt_boxes.to(teacher_boxes.device, dtype=teacher_boxes.dtype)
                        
                        # IoU ê³„ì‚°í•˜ì—¬ quality score ìƒì„±
                        ious = self.box_iou(teacher_boxes, gt_boxes)
                        quality = ious.max(dim=1)[0]
                        quality_scores.append(quality)
        
        elif isinstance(targets, dict):
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° - YOLODataset í‘œì¤€ í˜•íƒœ
            print("ğŸ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ targets ì²˜ë¦¬")
            batch_idx = targets.get('batch_idx', None)
            bboxes = targets.get('bboxes', None)
            cls = targets.get('cls', None)
            
            if batch_idx is not None and bboxes is not None:
                print(f"ğŸ” Batch indices: {batch_idx.shape if hasattr(batch_idx, 'shape') else batch_idx}")
                print(f"ğŸ” BBoxes: {bboxes.shape if hasattr(bboxes, 'shape') else bboxes}")
                print(f"ğŸ” Classes: {cls.shape if hasattr(cls, 'shape') else cls}")
                
                # ë°°ì¹˜ë³„ë¡œ GT ë°•ìŠ¤ ê·¸ë£¹í™”
                unique_batch_idx = torch.unique(batch_idx)
                for batch_i in unique_batch_idx:
                    # í˜„ì¬ ë°°ì¹˜ì— ì†í•˜ëŠ” GTë“¤
                    mask = batch_idx == batch_i
                    batch_bboxes = bboxes[mask]  # [num_gt, 4]
                    
                    if batch_bboxes.shape[0] > 0:
                        batch_i_int = int(batch_i.item())
                        # Teacher ì˜ˆì¸¡ê³¼ GT ë§¤ì¹­
                        teacher_conf = torch.sigmoid(objectness[batch_i_int])  # [N, 1]
                        high_conf_idx = teacher_conf.squeeze(-1) > 0.5  # [N] for bbox indexing
                        
                        if high_conf_idx.any():
                            teacher_boxes = bbox[batch_i_int][high_conf_idx]  # [num_valid, 4]
                            
                            # GT ë°•ìŠ¤ê°€ ìˆëŠ” ê²½ìš°ë§Œ IoU ê³„ì‚°
                            if batch_bboxes.shape[0] > 0:
                                # ì¢Œí‘œ í˜•ì‹ì´ ì´ë¯¸ xyxyì¸ì§€ xywhì¸ì§€ í™•ì¸ í•„ìš”
                                # ë””ë°”ì´ìŠ¤ ë° dtype ì •ë ¬
                                batch_bboxes = batch_bboxes.to(teacher_boxes.device, dtype=teacher_boxes.dtype)
                                ious = self.box_iou(teacher_boxes, batch_bboxes)
                                quality = ious.max(dim=1)[0]
                                quality_scores.append(quality)
            else:
                print("âš ï¸ batch_idx ë˜ëŠ” bboxesê°€ targetsì— ì—†ìŒ")
                
        else:
            # ë‹¤ë¥¸ í˜•íƒœì¸ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
            print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” targets í˜•íƒœ: {type(targets)}")
            return torch.tensor(0.0, device=bbox.device)
        
        if quality_scores:
            return torch.cat(quality_scores)
        else:
            return torch.tensor(0.0, device=bbox.device)
    
    def xywh_to_xyxy(self, bbox):
        """YOLO bbox í˜•ì‹ (cx, cy, w, h) â†’ (x1, y1, x2, y2) ë³€í™˜"""
        if bbox.shape[-1] != 4:
            print(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ bbox í˜•ì‹: {bbox.shape}")
            return bbox
            
        cx, cy, w, h = bbox[..., 0], bbox[..., 1], bbox[..., 2], bbox[..., 3]
        x1 = cx - w / 2
        y1 = cy - h / 2
        x2 = cx + w / 2
        y2 = cy + h / 2
        
        return torch.stack([x1, y1, x2, y2], dim=-1)
    
    def localization_quality_loss(self, student_bbox, student_obj, quality_scores):
        """Localization quality ì „ë‹¬ì„ ìœ„í•œ ì†ì‹¤"""
        if isinstance(quality_scores, torch.Tensor) and quality_scores.numel() > 0:
            # Studentì˜ confidenceê°€ Teacherì˜ localization qualityë¥¼ ë”°ë¼ê°€ë„ë¡
            return F.mse_loss(
                torch.sigmoid(student_obj).mean(),
                quality_scores.mean()
            )
        return torch.tensor(0.0, device=student_bbox.device)
    
    def align_outputs_intelligently(self, teacher_out, student_out):
        """
        Teacherì™€ Student ì¶œë ¥ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ì •ë ¬ (ì •ë³´ ì†ì‹¤ ìµœì†Œí™”)
        """
        print(f"ğŸ”§ ì •ë ¬ ì „ - Teacher: {teacher_out.shape}, Student: {student_out.shape}")
        
        # ë‹¤ì°¨ì› í…ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        batch_size = teacher_out.shape[0]
        teacher_seq_len = teacher_out.shape[1]
        student_seq_len = student_out.shape[1]
        feature_dim = teacher_out.shape[2]  # objectness: 1, bbox: 4
        
        # Teacherê°€ ë” ì‘ì€ ê²½ìš° (ì¼ë°˜ì ì¸ ê²½ìš°)
        if teacher_seq_len < student_seq_len:
            # Teacherë¥¼ Student í¬ê¸°ë¡œ í™•ì¥ (interpolation)
            # [B, seq, feat] â†’ [B, feat, seq] â†’ interpolate â†’ [B, feat, new_seq] â†’ [B, new_seq, feat]
            teacher_transposed = teacher_out.transpose(1, 2)  # [B, feat, seq]
            teacher_expanded = F.interpolate(
                teacher_transposed,
                size=student_seq_len,
                mode='linear',
                align_corners=False
            ).transpose(1, 2)  # [B, new_seq, feat]
            
            print(f"ğŸ“ˆ Teacher í™•ì¥: {teacher_out.shape} â†’ {teacher_expanded.shape}")
            return teacher_expanded, student_out
            
        # Studentê°€ ë” ì‘ì€ ê²½ìš° 
        elif student_seq_len < teacher_seq_len:
            # Studentë¥¼ Teacher í¬ê¸°ë¡œ í™•ì¥
            student_transposed = student_out.transpose(1, 2)
            student_expanded = F.interpolate(
                student_transposed,
                size=teacher_seq_len,
                mode='linear', 
                align_corners=False
            ).transpose(1, 2)
            
            print(f"ğŸ“ˆ Student í™•ì¥: {student_out.shape} â†’ {student_expanded.shape}")
            return teacher_out, student_expanded
            
        else:
            # ì´ë¯¸ ê°™ì€ í¬ê¸°
            print(f"âœ… í¬ê¸° ë™ì¼: {teacher_out.shape}")
            return teacher_out, student_out
